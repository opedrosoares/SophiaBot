#!/usr/bin/env python3
"""
Script para executar extraÃ§Ã£o completa de todas as normas ANTAQ
ATENÃ‡ÃƒO: Este processo pode demorar vÃ¡rias horas
"""

from Scrap import SophiaANTAQScraper
import time
import os

def main():
    print("ğŸš€ EXTRAÃ‡ÃƒO COMPLETA - NORMAS ANTAQ")
    print("âš ï¸  ATENÃ‡ÃƒO: Este processo pode demorar vÃ¡rias horas!")
    print("ğŸ’¡ Pressione Ctrl+C para interromper a qualquer momento")
    print("=" * 60)
    
    # ConfirmaÃ§Ã£o do usuÃ¡rio
    resposta = input("Deseja continuar com a extraÃ§Ã£o completa? (s/N): ").strip().lower()
    if resposta not in ['s', 'sim', 'y', 'yes']:
        print("âŒ ExtraÃ§Ã£o cancelada pelo usuÃ¡rio")
        return
    
    print("\nğŸ”„ Iniciando extraÃ§Ã£o completa...")
    start_time = time.time()
    
    # ConfiguraÃ§Ãµes para extraÃ§Ã£o completa
    scraper = SophiaANTAQScraper(
        delay=1.5,  # 1.5 segundos entre requisiÃ§Ãµes (uso responsÃ¡vel)
        verify_ssl=False
    )
    
    # Nome do arquivo principal (sempre o mesmo para updates incrementais)
    arquivo_principal = "shared/data/normas_antaq_completo.parquet"
    
    try:
        # Verifica se jÃ¡ existe arquivo com dados
        if os.path.exists(arquivo_principal):
            print(f"ğŸ“‚ Arquivo existente encontrado: {arquivo_principal}")
            existing_ids = scraper.load_existing_ids(arquivo_principal)
            print(f"ğŸ”‘ {len(existing_ids)} IDs jÃ¡ existentes no banco")
            print(f"ğŸ’¡ Modo INCREMENTAL: apenas normas novas serÃ£o adicionadas")
        else:
            print("ğŸ“‚ Iniciando nova base de dados completa")
            existing_ids = set()
        
        # ObtÃ©m GUID inicial
        scraper.get_initial_guid()
        
        # Extrai TODAS as pÃ¡ginas (sem limite)
        print("ğŸ“¥ Extraindo todas as pÃ¡ginas disponÃ­veis...")
        todos_dados = scraper.scrape_all_pages()  # SEM max_pages
        
        if todos_dados:
            print(f"ğŸ” Filtrando duplicatas de {len(todos_dados)} registros extraÃ­dos...")
            
            # Filtra duplicatas se hÃ¡ dados existentes
            if existing_ids:
                dados_novos = scraper.filter_duplicates(todos_dados, existing_ids)
            else:
                dados_novos = todos_dados
                print(f"ğŸ“‹ Primeira execuÃ§Ã£o: todos os {len(dados_novos)} registros sÃ£o novos")
            
            if dados_novos:
                # Salva dados (mescla com existentes)
                scraper.save_to_parquet(dados_novos, arquivo_principal, merge_with_existing=True)
                
                # EstatÃ­sticas finais
                elapsed_time = time.time() - start_time
                print(f"\nğŸ‰ EXTRAÃ‡ÃƒO COMPLETA FINALIZADA!")
                print(f"â±ï¸  Tempo total: {elapsed_time/3600:.1f} horas")
                print(f"ğŸ“Š Registros extraÃ­dos: {len(todos_dados)} total")
                print(f"ğŸ†• Registros NOVOS adicionados: {len(dados_novos)}")
                print(f"ğŸ—ƒï¸  Total no arquivo: {len(existing_ids) + len(dados_novos)} normas")
                print(f"ğŸ’¾ Arquivo salvo: {arquivo_principal}")
                print(f"ğŸ“ˆ Velocidade mÃ©dia: {len(todos_dados)/(elapsed_time/3600):.0f} normas/hora")
                
                # Cria backup com timestamp se houve mudanÃ§as significativas
                if len(dados_novos) > 10:
                    timestamp = time.strftime("%Y%m%d_%H%M%S")
                    backup_name = f"shared/backups/backup_normas_antaq_{timestamp}.parquet"
                    scraper.save_to_parquet(todos_dados, backup_name, merge_with_existing=False)
                    print(f"ğŸ’¾ Backup criado: {backup_name}")
            else:
                elapsed_time = time.time() - start_time
                print(f"\nğŸ“‹ BASE DE DADOS JÃ ATUALIZADA!")
                print(f"â±ï¸  Tempo de verificaÃ§Ã£o: {elapsed_time/60:.1f} minutos")
                print(f"ğŸ—ƒï¸  Total de normas no arquivo: {len(existing_ids)}")
                print(f"âœ… Nenhuma norma nova encontrada")
            
        else:
            print("âŒ Nenhum dado foi extraÃ­do")
            
    except KeyboardInterrupt:
        print(f"\nâš ï¸  ExtraÃ§Ã£o interrompida pelo usuÃ¡rio apÃ³s {(time.time()-start_time)/60:.1f} minutos")
        print("ğŸ’¡ Dados parciais podem ter sido salvos")
    except Exception as e:
        print(f"âŒ Erro durante extraÃ§Ã£o: {e}")

if __name__ == "__main__":
    main()