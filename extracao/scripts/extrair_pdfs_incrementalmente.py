#!/usr/bin/env python3
"""
Script para extraÃ§Ã£o incremental de conteÃºdo de PDFs
Permite extrair PDFs apenas das normas que ainda nÃ£o possuem conteÃºdo extraÃ­do
"""

from Scrap import SophiaANTAQScraper, PDFExtractor
import pandas as pd
import os
import time

def encontrar_base_dados():
    """
    Encontra a base de dados principal de normas
    """
    # Procura por arquivos parquet de normas
    candidatos = [
        "normas_antaq_completo.parquet",
        "normas_antaq.parquet"
    ]
    
    # Adiciona outros arquivos encontrados
    for arquivo in os.listdir('.'):
        if arquivo.endswith('.parquet') and 'normas' in arquivo.lower():
            if arquivo not in candidatos:
                candidatos.append(arquivo)
    
    # Encontra o arquivo mais recente
    arquivos_existentes = [f for f in candidatos if os.path.exists(f)]
    
    if not arquivos_existentes:
        return None
    
    arquivo_principal = max(arquivos_existentes, key=os.path.getctime)
    return arquivo_principal

def analisar_situacao_pdfs(arquivo):
    """
    Analisa quantos PDFs jÃ¡ foram extraÃ­dos
    """
    print(f"ğŸ“Š ANÃLISE DA SITUAÃ‡ÃƒO ATUAL")
    print("=" * 35)
    
    df = pd.read_parquet(arquivo)
    
    total = len(df)
    com_link_pdf = df['link_pdf'].notna().sum()
    
    # Verifica se jÃ¡ tem coluna de conteÃºdo PDF
    if 'conteudo_pdf' in df.columns:
        com_conteudo = df['conteudo_pdf'].str.len().gt(0).sum()
        sem_conteudo = com_link_pdf - com_conteudo
        
        print(f"ğŸ“‹ Total de normas: {total}")
        print(f"ğŸ“„ Com link PDF: {com_link_pdf} ({com_link_pdf/total*100:.1f}%)")
        print(f"âœ… PDFs jÃ¡ extraÃ­dos: {com_conteudo} ({com_conteudo/com_link_pdf*100:.1f}%)")
        print(f"â³ PDFs pendentes: {sem_conteudo} ({sem_conteudo/com_link_pdf*100:.1f}%)")
        
        return {
            'total': total,
            'com_link': com_link_pdf,
            'extraidos': com_conteudo,
            'pendentes': sem_conteudo,
            'tem_coluna_pdf': True
        }
    else:
        print(f"ğŸ“‹ Total de normas: {total}")
        print(f"ğŸ“„ Com link PDF: {com_link_pdf} ({com_link_pdf/total*100:.1f}%)")
        print(f"âš ï¸  Nenhum PDF foi extraÃ­do ainda (coluna conteudo_pdf nÃ£o existe)")
        
        return {
            'total': total,
            'com_link': com_link_pdf,
            'extraidos': 0,
            'pendentes': com_link_pdf,
            'tem_coluna_pdf': False
        }

def extrair_pdfs_pendentes(arquivo, max_pdfs=None):
    """
    Extrai conteÃºdo dos PDFs que ainda nÃ£o foram processados
    """
    print(f"\nğŸ”„ EXTRAÃ‡ÃƒO INCREMENTAL DE PDFs")
    print("=" * 40)
    
    df = pd.read_parquet(arquivo)
    
    # Identifica normas com PDF pendente
    if 'conteudo_pdf' in df.columns:
        # Normas com link PDF mas sem conteÃºdo extraÃ­do
        pendentes = df[
            (df['link_pdf'].notna()) & 
            (df['conteudo_pdf'].str.len().eq(0) | df['conteudo_pdf'].isna())
        ]
    else:
        # Todas as normas com link PDF sÃ£o pendentes
        pendentes = df[df['link_pdf'].notna()]
    
    if len(pendentes) == 0:
        print("âœ… Todos os PDFs jÃ¡ foram extraÃ­dos!")
        return df
    
    # Limita quantidade se especificado
    if max_pdfs and len(pendentes) > max_pdfs:
        pendentes = pendentes.head(max_pdfs)
        print(f"ğŸ¯ Processando apenas {max_pdfs} PDFs (de {len(df[df['link_pdf'].notna()])} pendentes)")
    else:
        print(f"ğŸ¯ Processando {len(pendentes)} PDFs pendentes")
    
    # Cria extrator de PDF
    scraper = SophiaANTAQScraper(delay=1.0, extract_pdf_content=False)
    pdf_extractor = PDFExtractor(scraper.session, timeout=30)
    
    # Adiciona colunas de PDF se nÃ£o existirem
    if 'conteudo_pdf' not in df.columns:
        df['conteudo_pdf'] = ''
        df['metodo_extracao'] = ''
        df['tamanho_pdf'] = 0
        df['paginas_extraidas'] = 0
        df['erro_extracao'] = ''
    
    # Processa cada PDF pendente
    sucessos = 0
    erros = 0
    
    print(f"\nğŸ“¥ Iniciando extraÃ§Ã£o de PDFs...")
    start_time = time.time()
    
    for idx, (index, row) in enumerate(pendentes.iterrows(), 1):
        codigo = row['codigo_registro']
        titulo = row['titulo'][:40] + "..."
        pdf_url = row['link_pdf']
        
        print(f"ğŸ“„ [{idx}/{len(pendentes)}] ID {codigo}: {titulo}")
        
        try:
            # Extrai conteÃºdo do PDF
            resultado = pdf_extractor.extract_pdf_content(pdf_url)
            
            # Atualiza o DataFrame
            df.loc[index, 'conteudo_pdf'] = resultado.get('conteudo_pdf', '')
            df.loc[index, 'metodo_extracao'] = resultado.get('metodo_extracao', '')
            df.loc[index, 'tamanho_pdf'] = resultado.get('tamanho_pdf', 0)
            df.loc[index, 'paginas_extraidas'] = resultado.get('paginas_extraidas', 0)
            df.loc[index, 'erro_extracao'] = resultado.get('erro_extracao', '')
            
            if resultado.get('conteudo_pdf'):
                chars = len(resultado['conteudo_pdf'])
                metodo = resultado['metodo_extracao']
                print(f"   âœ… ExtraÃ­do: {chars} chars via {metodo}")
                sucessos += 1
            else:
                erro = resultado.get('erro_extracao', 'Erro desconhecido')
                print(f"   âŒ Erro: {erro}")
                erros += 1
            
        except Exception as e:
            print(f"   âŒ ExceÃ§Ã£o: {e}")
            df.loc[index, 'erro_extracao'] = f"ExceÃ§Ã£o: {str(e)}"
            erros += 1
        
        # Pausa entre PDFs
        time.sleep(0.5)
        
        # Salva progresso a cada 10 PDFs
        if idx % 10 == 0:
            backup_file = f"backup_progresso_{int(time.time())}.parquet"
            df.to_parquet(backup_file, index=False)
            print(f"   ğŸ’¾ Progresso salvo em: {backup_file}")
    
    # EstatÃ­sticas finais
    elapsed_time = time.time() - start_time
    
    print(f"\nğŸ“Š EXTRAÃ‡ÃƒO CONCLUÃDA:")
    print(f"   â±ï¸  Tempo total: {elapsed_time/60:.1f} minutos")
    print(f"   âœ… Sucessos: {sucessos}")
    print(f"   âŒ Erros: {erros}")
    print(f"   ğŸ“ˆ Taxa de sucesso: {sucessos/(sucessos+erros)*100:.1f}%")
    print(f"   ğŸš€ Velocidade: {len(pendentes)/(elapsed_time/60):.1f} PDFs/min")
    
    return df

def salvar_dados_atualizados(df, arquivo_original):
    """
    Salva os dados atualizados
    """
    print(f"\nğŸ’¾ SALVANDO DADOS ATUALIZADOS")
    print("=" * 35)
    
    # Cria backup do arquivo original
    timestamp = int(time.time())
    backup_original = f"backup_original_{timestamp}.parquet"
    
    if os.path.exists(arquivo_original):
        os.rename(arquivo_original, backup_original)
        print(f"ğŸ“¦ Backup do original: {backup_original}")
    
    # Salva dados atualizados
    df.to_parquet(arquivo_original, index=False)
    print(f"ğŸ’¾ Dados atualizados salvos em: {arquivo_original}")
    
    # Cria tambÃ©m versÃ£o com timestamp
    arquivo_timestamped = f"normas_com_pdfs_{timestamp}.parquet"
    df.to_parquet(arquivo_timestamped, index=False)
    print(f"ğŸ“„ CÃ³pia timestamped: {arquivo_timestamped}")
    
    # EstatÃ­sticas finais
    total = len(df)
    com_conteudo = df['conteudo_pdf'].str.len().gt(0).sum()
    tamanho_medio = df[df['conteudo_pdf'].str.len() > 0]['conteudo_pdf'].str.len().mean()
    
    print(f"\nğŸ“Š ESTATÃSTICAS FINAIS:")
    print(f"   ğŸ“‹ Total de normas: {total}")
    print(f"   ğŸ“„ PDFs com conteÃºdo: {com_conteudo}")
    print(f"   ğŸ“Š Cobertura: {com_conteudo/total*100:.1f}%")
    print(f"   ğŸ“ Tamanho mÃ©dio: {tamanho_medio:.0f} chars")

def main():
    """
    FunÃ§Ã£o principal
    """
    print("ğŸ”„ EXTRAÃ‡ÃƒO INCREMENTAL DE PDFs - NORMAS ANTAQ")
    print("=" * 55)
    
    try:
        # Encontra base de dados
        arquivo = encontrar_base_dados()
        
        if not arquivo:
            print("âŒ Nenhuma base de dados de normas encontrada")
            print("ğŸ’¡ Execute primeiro: python3 Scrap.py ou python3 executar_completo.py")
            return
        
        print(f"ğŸ“‚ Base de dados encontrada: {arquivo}")
        
        # Analisa situaÃ§Ã£o atual
        situacao = analisar_situacao_pdfs(arquivo)
        
        if situacao['pendentes'] == 0:
            print(f"\nâœ… Todos os PDFs jÃ¡ foram extraÃ­dos! Nada a fazer.")
            return
        
        # Pergunta se deve continuar
        print(f"\nâ“ Deseja extrair conteÃºdo dos {situacao['pendentes']} PDFs pendentes?")
        print(f"âš ï¸  Isso pode demorar ~{situacao['pendentes']*2/60:.0f} minutos")
        
        resposta = input("Continuar? (s/N): ").strip().lower()
        if resposta not in ['s', 'sim', 'y', 'yes']:
            print("âŒ ExtraÃ§Ã£o cancelada pelo usuÃ¡rio")
            return
        
        # Pergunta sobre limite
        limite_str = input(f"Limite de PDFs (Enter para todos os {situacao['pendentes']}): ").strip()
        max_pdfs = None
        if limite_str:
            try:
                max_pdfs = int(limite_str)
                print(f"ğŸ¯ Limitando a {max_pdfs} PDFs")
            except ValueError:
                print("âš ï¸ Limite invÃ¡lido, processando todos")
        
        # Extrai PDFs
        df_atualizado = extrair_pdfs_pendentes(arquivo, max_pdfs)
        
        # Salva dados atualizados
        salvar_dados_atualizados(df_atualizado, arquivo)
        
        print(f"\nğŸ‰ EXTRAÃ‡ÃƒO INCREMENTAL CONCLUÃDA!")
        print(f"ğŸ’¡ Agora vocÃª pode:")
        print(f"   ğŸ” Usar pandas para buscar por conteÃºdo")
        print(f"   ğŸ“Š Fazer anÃ¡lises estatÃ­sticas do texto")
        print(f"   ğŸ”„ Executar novamente para processar mais PDFs")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸ ExtraÃ§Ã£o interrompida pelo usuÃ¡rio")
        print(f"ğŸ’¡ Progresso pode ter sido salvo automaticamente")
    except Exception as e:
        print(f"âŒ Erro durante extraÃ§Ã£o: {e}")

if __name__ == "__main__":
    main()