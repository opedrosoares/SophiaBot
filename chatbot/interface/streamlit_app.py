#!/usr/bin/env python3
"""
Interface Streamlit para o Chatbot ANTAQ
Interface amig√°vel para consultas sobre normas da ANTAQ
"""

import streamlit as st
import streamlit.components.v1 as components
import os
import sys
from pathlib import Path
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import json
from typing import Dict, List, Any
import time
import random

# Adicionar diret√≥rio do projeto ao path
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from core.vector_store import VectorStoreANTAQ
from core.rag_system import RAGSystemANTAQ
from config.config import OPENAI_API_KEY, OPENAI_MODEL, CHROMA_PERSIST_DIRECTORY, DATA_PATH

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Chatbot ANTAQ - Consultas sobre Normas",
    page_icon="‚öì",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://www.gov.br/antaq/pt-br',
        'Report a bug': 'mailto:gpf@antaq.gov.br',
        'About': """
        # Chatbot ANTAQ
        
        Sistema inteligente para consultas sobre normas da 
        Ag√™ncia Nacional de Transportes Aquavi√°rios.
        
        **Desenvolvido com:**
        - OpenAI GPT-4
        - ChromaDB (Banco Vetorial)
        - Streamlit
        - T√©cnicas RAG (Retrieval-Augmented Generation)
        """
    }
)

# Carregar CSS customizado
def load_css():
    css_file = Path(__file__).parent / "styles.css"
    if css_file.exists():
        with open(css_file, 'r', encoding='utf-8') as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

# Carregar estilos CSS
load_css()

class ChatbotANTAQApp:
    """Classe principal da aplica√ß√£o Streamlit"""
    
    def __init__(self):
        """Inicializa a aplica√ß√£o"""
        self.initialize_session_state()
        
    def initialize_session_state(self):
        """Inicializa estados da sess√£o"""
        
        # Estados principais
        if 'rag_system' not in st.session_state:
            st.session_state.rag_system = None
            
        if 'vector_store' not in st.session_state:
            st.session_state.vector_store = None
            
        if 'messages' not in st.session_state:
            st.session_state.messages = []
            
        if 'system_initialized' not in st.session_state:
            st.session_state.system_initialized = False
            
        # Configura√ß√µes
        if 'show_sources' not in st.session_state:
            st.session_state.show_sources = True
            
        if 'max_results' not in st.session_state:
            st.session_state.max_results = 8
            
        if 'model_choice' not in st.session_state:
            st.session_state.model_choice = OPENAI_MODEL
            
        # Estat√≠sticas
        if 'total_queries' not in st.session_state:
            st.session_state.total_queries = 0
            
        if 'session_start' not in st.session_state:
            st.session_state.session_start = datetime.now()
            
        # Estados para perguntas de exemplo
        if 'shuffled_questions' not in st.session_state:
            st.session_state.shuffled_questions = []
            
        if 'preset_prompt' not in st.session_state:
            st.session_state.preset_prompt = ""
            
        if 'process_preset_prompt' not in st.session_state:
            st.session_state.process_preset_prompt = False
            
        if 'show_all_questions' not in st.session_state:
            st.session_state.show_all_questions = False
    
    def render_header(self):
        """Renderiza o cabe√ßalho da aplica√ß√£o"""
        
        st.markdown("""
        <div class="main-header">
            <h1>Chatbot Sophia - ANTAQ</h1>
            <p>Sistema Inteligente para Consultas sobre Normas de Transporte Aquavi√°rio</p>
        </div>
        """, unsafe_allow_html=True)
    
    def render_sidebar(self):
        """Renderiza a barra lateral com configura√ß√µes"""
        
        with st.sidebar:
            
            # Inicializar sistema automaticamente se n√£o estiver inicializado
            # if not st.session_state.system_initialized:
                # if st.button("üöÄ Inicializar Sistema", type="primary"):
                    # self.initialize_system()
            
            # Configura√ß√µes avan√ßadas
            if st.session_state.system_initialized:
                st.subheader("üéõÔ∏è Configura√ß√µes Avan√ßadas")
                
                # Modelo GPT
                model_options = ["gpt-4.1-nano", "gpt-4", "gpt-3.5-turbo", "gpt-4-turbo"]
                current_model = st.session_state.model_choice
                
                # Se o modelo atual n√£o estiver na lista, usar o primeiro
                if current_model not in model_options:
                    current_model = model_options[0]
                    st.session_state.model_choice = current_model
                
                st.session_state.model_choice = st.selectbox(
                    "Modelo GPT",
                    options=model_options,
                    index=model_options.index(current_model),
                    help="Escolha o modelo GPT para gerar respostas"
                )
                
                # N√∫mero de resultados
                st.session_state.max_results = st.slider(
                    "Documentos para Contexto",
                    min_value=3,
                    max_value=15,
                    value=st.session_state.max_results,
                    help="N√∫mero de documentos relevantes para incluir no contexto"
                )
                
                # Mostrar fontes
                st.session_state.show_sources = st.checkbox(
                    "Mostrar Fontes",
                    value=st.session_state.show_sources,
                    help="Exibir documentos fonte das respostas"
                )
                
                st.divider()
                
                # Estat√≠sticas da sess√£o
                st.subheader("üìä Estat√≠sticas da Sess√£o")
                
                duration = datetime.now() - st.session_state.session_start
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Consultas", st.session_state.total_queries)
                with col2:
                    st.metric("Dura√ß√£o", f"{duration.seconds//60}min")
                
                # A√ß√µes
                st.subheader("üîß A√ß√µes")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("üóëÔ∏è Limpar Chat"):
                        self.clear_chat()
                        st.rerun()
                
                with col2:
                    if st.button("üì• Exportar Chat"):
                        self.export_chat()
                
                # Informa√ß√µes do sistema
                if st.expander("‚ÑπÔ∏è Informa√ß√µes do Sistema"):
                    if st.session_state.vector_store:
                        try:
                            stats = st.session_state.vector_store.get_collection_stats()
                            
                            if 'error' in stats:
                                st.error(f"Erro ao carregar estat√≠sticas: {stats['error']}")
                                return
                            
                            st.write("**üìä Banco de Dados:**")
                            st.write(f"‚Ä¢ Total de registros: {stats.get('total_chunks', 'N/A'):,}")
                            st.write(f"‚Ä¢ Normas √∫nicas: {stats.get('total_normas_unicas', 'N/A'):,}")
                            
                            # Tipos de normas
                            if 'tipos_normas' in stats and stats['tipos_normas']:
                                st.write("**üìã Tipos de Normas:**")
                                for tipo, count in list(stats['tipos_normas'].items())[:6]:
                                    st.write(f"‚Ä¢ {tipo}: {count:,}")
                            
                            # Situa√ß√µes das normas
                            if 'situacoes' in stats and stats['situacoes']:
                                st.write("**‚öñÔ∏è Situa√ß√£o das Normas:**")
                                for situacao, count in list(stats['situacoes'].items())[:3]:
                                    st.write(f"‚Ä¢ {situacao}: {count:,}")
                            
                            # Top assuntos
                            if 'top_assuntos' in stats and stats['top_assuntos']:
                                st.write("**üè∑Ô∏è Top Assuntos:**")
                                for assunto, count in list(stats['top_assuntos'].items())[:5]:
                                    if assunto and assunto.strip():
                                        st.write(f"‚Ä¢ {assunto}: {count}")
                                    else:
                                        st.write(f"‚Ä¢ Sem assunto: {count}")
                            
                            # Distribui√ß√£o por ano
                            if 'distribuicao_anos' in stats and stats['distribuicao_anos']:
                                anos_ordenados = sorted(stats['distribuicao_anos'].items(), reverse=True)
                                if anos_ordenados:
                                    st.write("**üìÖ Per√≠odo:**")
                                    ano_mais_recente = anos_ordenados[0][0]
                                    ano_mais_antigo = anos_ordenados[-1][0]
                                    st.write(f"‚Ä¢ {ano_mais_antigo} - {ano_mais_recente}")
                                    st.write(f"‚Ä¢ Ano mais recente: {ano_mais_recente} ({anos_ordenados[0][1]} registros)")
                        
                        except Exception as e:
                            st.error(f"Erro ao carregar estat√≠sticas: {str(e)}")
    
    def initialize_system(self):
        """Inicializa o sistema RAG"""
        
        try:
            with st.spinner("üîÑ Inicializando sistema..."):
                
                # Inicializar vector store
                st.session_state.vector_store = VectorStoreANTAQ(
                    openai_api_key=OPENAI_API_KEY,
                    persist_directory=str(CHROMA_PERSIST_DIRECTORY)
                )
                
                # Verificar se precisa carregar dados
                if not DATA_PATH.exists():
                    st.error(f"‚ùå Arquivo de dados n√£o encontrado: {DATA_PATH}")
                    return
                
                # Carregar dados se necess√°rio
                success = st.session_state.vector_store.load_and_process_data(
                    str(DATA_PATH),
                    force_rebuild=False
                )
                
                if not success:
                    st.error("‚ùå Erro ao carregar dados no banco vetorial")
                    return
                
                # Inicializar RAG system
                st.session_state.rag_system = RAGSystemANTAQ(
                    openai_api_key=OPENAI_API_KEY,
                    vector_store=st.session_state.vector_store,
                    model=OPENAI_MODEL
                )
                
                st.session_state.system_initialized = True
                st.success("‚úÖ Sistema inicializado com sucesso!")
                
        except Exception as e:
            st.error(f"‚ùå Erro ao inicializar sistema: {str(e)}")
            st.session_state.system_initialized = False
    
    def generate_example_questions(self):
        """Gera perguntas de exemplo din√¢micas"""
        
        if not st.session_state.shuffled_questions:
            preset_questions = [
                "Como funciona o licenciamento de terminais portu√°rios?",
                "Quais s√£o as tarifas para navega√ß√£o interior?",
                "O que √© necess√°rio para autoriza√ß√£o de opera√ß√£o portu√°ria?",
                "Quais normas regulam o transporte de cargas perigosas?",
                "Como √© feita a fiscaliza√ß√£o de embarca√ß√µes?",
                "Quais s√£o os requisitos para concess√£o de terminais?",
                "Como funciona o sistema de tarifas portu√°rias?",
                "Quais s√£o as normas para transporte de passageiros?",
                "Como √© regulamentado o transporte de cont√™ineres?",
                "Quais s√£o as obriga√ß√µes dos operadores portu√°rios?",
                "Como funciona o sistema de monitoramento de embarca√ß√µes?"
            ]
            random.shuffle(preset_questions)
            st.session_state.shuffled_questions = preset_questions
    
    def render_example_questions(self):
        """Renderiza as perguntas de exemplo"""
        
        self.generate_example_questions()
        
        questions_to_show = st.session_state.shuffled_questions
        questions_limit = len(questions_to_show) if st.session_state.show_all_questions else 3

        for i, q in enumerate(questions_to_show[:questions_limit]):
            if st.button(q, key=f"q_button_{i}", use_container_width=True):
                st.session_state.preset_prompt = q
                st.session_state.process_preset_prompt = True
                st.rerun()

        if not st.session_state.show_all_questions and len(questions_to_show) > 3:
            if st.button("‚ûï Ver mais exemplos", key="show_more", use_container_width=True):
                st.session_state.show_all_questions = True
                st.rerun()
    
    def render_chat_interface(self):
        """Renderiza a interface de chat"""
        
        if not st.session_state.system_initialized:
            st.error("‚ùå Erro ao inicializar o sistema. Verifique as configura√ß√µes.")
            return
        
        # Exibir hist√≥rico do chat usando st.chat_message
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                if isinstance(message["content"], tuple):
                    text_content, image_content = message["content"]
                    st.markdown(text_content)
                    if image_content:
                        st.image(image_content, use_container_width=True)
                else:
                    st.markdown(message["content"])
                
                # Mostrar fontes se habilitado
                if (message["role"] == "assistant" and 
                    st.session_state.show_sources and 
                    message.get('sources')):
                    with st.expander(f"üìö Fontes consultadas ({len(message['sources'])} documentos)"):
                        self.render_sources(message['sources'])
        
        # Perguntas de exemplo (apenas se n√£o h√° mensagens)
        if not st.session_state.messages:
            st.markdown("### Bem-vindo ao Chatbo Sophia - ANTAQ!")
            st.markdown("**Exemplos de perguntas que voc√™ pode fazer:**")
            self.render_example_questions()
        
        # √Årea de entrada usando st.chat_input
        prompt = st.chat_input("Pergunte-me sobre normas da ANTAQ...", key="chat_input")
        
        # Processar entrada
        if prompt:
            self.process_user_query(prompt)
            st.rerun()
        
        # Processar perguntas de exemplo
        if st.session_state.get('process_preset_prompt'):
            preset_prompt = st.session_state.get('preset_prompt')
            st.session_state.process_preset_prompt = False
            if preset_prompt:
                self.process_user_query(preset_prompt)
                st.rerun()
    
    def process_user_query(self, query: str):
        """Processa uma consulta do usu√°rio"""
        
        try:
            # Adicionar mensagem do usu√°rio
            st.session_state.messages.append({"role": "user", "content": query})
            
            # Atualizar estat√≠sticas
            st.session_state.total_queries += 1
            
            # Processar consulta
            with st.chat_message("assistant"):
                with st.spinner("ü§î Analisando sua pergunta..."):
                    result = st.session_state.rag_system.query(
                        user_query=query,
                        n_results=st.session_state.max_results
                    )
                
                # Exibir resposta
                st.markdown(result['response'])
                
                # Mostrar fontes se habilitado
                if st.session_state.show_sources and result.get('sources'):
                    with st.expander(f"üìö Fontes consultadas ({len(result['sources'])} documentos)"):
                        self.render_sources(result['sources'])
            
            # Adicionar resposta ao hist√≥rico
            assistant_message = {
                'role': 'assistant',
                'content': result['response'],
                'sources': result.get('sources', []),
                'metadata': result.get('metadata', {}),
                'timestamp': datetime.now()
            }
            st.session_state.messages.append(assistant_message)
            
            # Scroll autom√°tico para a √∫ltima mensagem
            components.html(
                """
                <script>
                    setTimeout(function() {
                        var stMain = window.parent.document.getElementsByClassName("stMain")[0];
                        if (stMain) { stMain.scrollTo({ top: stMain.scrollHeight, behavior: 'smooth' }); }
                    }, 200);
                </script>
                """
            )
            
        except Exception as e:
            st.error(f"‚ùå Erro ao processar consulta: {str(e)}")
    
    def render_sources(self, sources: List[Dict[str, Any]]):
        """Renderiza as fontes consultadas"""
        
        for i, source in enumerate(sources, 1):
            relevance = source.get('relevance_score', 0)
            relevance_color = "üü¢" if relevance > 0.8 else "üü°" if relevance > 0.6 else "üî¥"
            
            st.markdown(f"""
            <div class="source-card">
                <h4>{i}. {f'<a href="{source.get("link_pdf")}" target="_blank">{source.get("titulo", "N/A")} ‚ÜóÔ∏è</a>' if source.get("link_pdf") and source.get("link_pdf") != "N/A" else source.get("titulo", "N/A")}</h4>
                <p><strong>C√≥digo:</strong> {source.get('codigo_registro', 'N/A')}</p>
                <p><strong>Assunto:</strong> {source.get('assunto', 'N/A')}</p>
                <p><strong>Situa√ß√£o:</strong> {source.get('situacao', 'N/A')}</p>
                <p><strong>Data:</strong> {datetime.strptime(source.get('assinatura', ''), '%Y-%m-%d').strftime('%d/%m/%Y') if source.get('assinatura', '') not in ['', 'N/A', None] else 'N/A'}</p>
                <p><strong>Relev√¢ncia:</strong>{relevance_color} {relevance:.1%}</p>
            </div>
            """, unsafe_allow_html=True)
    
    def clear_chat(self):
        """Limpa o hist√≥rico do chat"""
        st.session_state.messages = []
        if st.session_state.rag_system:
            st.session_state.rag_system.clear_history()
        st.success("üóëÔ∏è Chat limpo com sucesso!")
    
    def export_chat(self):
        """Exporta o hist√≥rico do chat"""
        try:
            if not st.session_state.messages:
                st.warning("‚ö†Ô∏è N√£o h√° conversa para exportar")
                return
            
            # Preparar dados para exporta√ß√£o
            export_data = {
                'exported_at': datetime.now().isoformat(),
                'total_messages': len(st.session_state.messages),
                'session_duration': str(datetime.now() - st.session_state.session_start),
                'conversation': []
            }
            
            for msg in st.session_state.messages:
                export_msg = {
                    'role': msg['role'],
                    'content': msg['content'],
                    'timestamp': msg.get('timestamp', datetime.now()).isoformat() if isinstance(msg.get('timestamp'), datetime) else str(msg.get('timestamp', ''))
                }
                
                if msg['role'] == 'assistant' and 'sources' in msg:
                    export_msg['sources_count'] = len(msg['sources'])
                    export_msg['metadata'] = msg.get('metadata', {})
                
                export_data['conversation'].append(export_msg)
            
            # Criar arquivo JSON
            export_json = json.dumps(export_data, ensure_ascii=False, indent=2)
            
            # Oferecer download
            st.download_button(
                label="üì• Baixar conversa",
                data=export_json,
                file_name=f"conversa_antaq_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
            
        except Exception as e:
            st.error(f"‚ùå Erro ao exportar conversa: {str(e)}")
    
    def render_dashboard(self):
        """Renderiza dashboard com estat√≠sticas"""
        
        if not st.session_state.system_initialized:
            return
        
        with st.expander("üìä Dashboard"):
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "Consultas na Sess√£o",
                    st.session_state.total_queries,
                    delta=None
                )
            
            with col2:
                messages_count = len([m for m in st.session_state.messages if m['role'] == 'user'])
                st.metric(
                    "Mensagens",
                    messages_count,
                    delta=None
                )
            
            with col3:
                duration = datetime.now() - st.session_state.session_start
                st.metric(
                    "Tempo de Sess√£o",
                    f"{duration.seconds//60}min",
                    delta=None
                )
            
            with col4:
                avg_response_time = "< 10s"  # Estimativa
                st.metric(
                    "Tempo M√©dio",
                    avg_response_time,
                    delta=None
                )
    
    def run(self):
        """Executa a aplica√ß√£o"""
        
        # Renderizar componentes
        self.render_header()
        self.render_sidebar()
        
        # Inicializar sistema automaticamente na primeira execu√ß√£o
        if not st.session_state.system_initialized:
            with st.spinner("üîÑ Inicializando sistema automaticamente..."):
                self.initialize_system()
        
        self.render_dashboard()
        self.render_chat_interface()
        
        # Footer
        st.markdown("---")
        st.markdown("""
        <div style="text-align: center; color: #666;">
            <p>Chatbot Sophia - ANTAQ - Sistema inteligente para consultas sobre normas de transporte aquavi√°rio</p>
            <p>Desenvolvido com OpenAI GPT-4 ‚Ä¢ ChromaDB ‚Ä¢ Streamlit</p>
        </div>
        """, unsafe_allow_html=True)

def main():
    """Fun√ß√£o principal"""
    app = ChatbotANTAQApp()
    app.run()

if __name__ == "__main__":
    main()